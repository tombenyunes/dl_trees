{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTV4jWZMYMlu"
      },
      "source": [
        "# **Detectron2 setup** (run once)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZus4xFegIct"
      },
      "source": [
        "Clone forked repo and build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SzQ3tm-ZF-r"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tombenyunes/detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f0rgU0pZ6Rt"
      },
      "outputs": [],
      "source": [
        "!pip install -e /content/detectron2/ --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZmixUpYrQLv"
      },
      "source": [
        "# **Detectron2 training and visualisation** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Sy6RQ4PWE5X"
      },
      "outputs": [],
      "source": [
        "train = False\n",
        "train_data_path = \"/content/drive/MyDrive/_datasets/_masks/\" + \"acacia\" + \"/\"\n",
        "train_model_dir = \"/content/drive/MyDrive/_models/_detectron/\" + \"acacia\" + \"/\"\n",
        "\n",
        "saved_model_dir = \"/content/drive/MyDrive/_models/_detectron/\" + \"acacia\" + \"/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM-ePp1yT8e2"
      },
      "source": [
        "### **Prepare the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3nCvm1mTbK_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPhV9QzOTggW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "\n",
        "from detectron2.structures import BoxMode\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
        "\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SueKIDl1f_Ib"
      },
      "source": [
        "Process image metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPDbZ10mTgdf"
      },
      "outputs": [],
      "source": [
        "def get_data_dicts(directory, classes):\n",
        "    dataset_dicts = []\n",
        "\n",
        "    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n",
        "        json_file = os.path.join(directory, filename)\n",
        "        with open(json_file) as f:\n",
        "            img_anns = json.load(f)\n",
        "\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "      \n",
        "        annos = img_anns[\"shapes\"]\n",
        "        objs = []\n",
        "        \n",
        "        for anno in annos:\n",
        "            px = [a[0] for a in anno['points']] # x coord\n",
        "            py = [a[1] for a in anno['points']] # y-coord\n",
        "            poly = [(x, y) for x, y in zip(px, py)] # poly for segmentation\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": classes.index(anno['label']),\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj)\n",
        "            \n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "\n",
        "    return dataset_dicts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efhIdDaue_Lb"
      },
      "source": [
        "Register the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGt-e47XTgas"
      },
      "outputs": [],
      "source": [
        "DatasetCatalog.clear() # incase dataset is already registered\n",
        "\n",
        "classes = ['tree']\n",
        "\n",
        "data_path = train_data_path\n",
        "\n",
        "DatasetCatalog.register(\n",
        "    \"category_train\", \n",
        "    lambda: get_data_dicts(data_path, classes)\n",
        ")\n",
        "MetadataCatalog.get(\"category_train\").set(thing_classes=classes)\n",
        "\n",
        "microcontroller_metadata = MetadataCatalog.get(\"category_train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3pwLAkXw9wi"
      },
      "source": [
        "### **Configure/Train**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUDK8zsnbGG6"
      },
      "source": [
        "Configure the model - either train the model or use saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZswZczBTgWx"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"category_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "if (train):\n",
        "  cfg.OUTPUT_DIR = train_model_dir\n",
        "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "  \n",
        "  trainer = DefaultTrainer(cfg) \n",
        "  trainer.resume_or_load(resume=False)\n",
        "  trainer.train()\n",
        "\n",
        "else:\n",
        "  cfg.OUTPUT_DIR = saved_model_dir\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.DATASETS.TEST = (\"category_test\", )\n",
        "\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt9FHxn0xGlq"
      },
      "source": [
        "### **Inference**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emqXwZyfMNKg"
      },
      "source": [
        "#### Mask and Crop Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K35nFoaHdTmr"
      },
      "outputs": [],
      "source": [
        "inference_input_dir = \"/content/drive/MyDrive/_inference/\" + \"winter\" + \"/\"\n",
        "inference_output_dir = \"/content/drive/MyDrive/_output/_detectron/\" + \"merged\" + \"/\"\n",
        "\n",
        "inference_input_dir = \"/content/drive/MyDrive/_output/_stylegan_with_background/\"\n",
        "inference_output_dir = \"/content/drive/MyDrive/_output/_detectron/using_stylegan_background_input_data/first_pass/\"\n",
        "\n",
        "os.makedirs(inference_output_dir, exist_ok=True)\n",
        "\n",
        "# img = cv2.imread(\"/content/drive/MyDrive/masks/test_images/8.jpg\")\n",
        "# cv2_imshow(img)    # raw image\n",
        "\n",
        "for img in os.listdir(inference_input_dir):\n",
        "  image_name = img\n",
        "  print(image_name[:-4])\n",
        "  img = cv2.imread(os.path.join(inference_input_dir, img))\n",
        "\n",
        "  outputs = predictor(img)\n",
        "\n",
        "  v = Visualizer(img[:, :, ::-1],\n",
        "                  metadata=microcontroller_metadata, \n",
        "                  scale=1.0, \n",
        "                  instance_mode=ColorMode.IMAGE_BW\n",
        "  )\n",
        "\n",
        "  v2 = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  # v2 = v.draw_masked_area(outputs[\"instances\"].to(\"cpu\"), True)\n",
        "\n",
        "  # assert v.get_image_score().size() != torch.Size([0])    # tree must be detected\n",
        "\n",
        "  if (v.get_image_score().size() != torch.Size([0])):\n",
        "\n",
        "    img = v2.get_image()\n",
        "    # cv2_imshow(img)    # detected image\n",
        "\n",
        "    if (v.get_image_boxes().tensor.size(0) != 0):\n",
        "\n",
        "      y1 = int(v.get_image_boxes().tensor[0][1])\n",
        "      y2 = int(v.get_image_boxes().tensor[0][3])\n",
        "      x1 = int(v.get_image_boxes().tensor[0][0])\n",
        "      x2 = int(v.get_image_boxes().tensor[0][2])\n",
        "\n",
        "      img = img[y1:y2, x1:x2, ::-1]\n",
        "\n",
        "    # cv2_imshow(img)    # cropped image\n",
        "\n",
        "    xsize = img.shape[1]\n",
        "    ysize = img.shape[0]\n",
        "    if (xsize != ysize):\n",
        "      lsize = max(xsize, ysize)\n",
        "      if (xsize == lsize):\n",
        "        tbuff = int(math.ceil((xsize - ysize) / 2))\n",
        "        bbuff = int(math.floor((xsize - ysize) / 2))\n",
        "        lbuff = 0\n",
        "        rbuff = 0\n",
        "      elif (ysize == lsize):\n",
        "        tbuff = 0\n",
        "        bbuff = 0\n",
        "        lbuff = int(math.ceil((ysize - xsize) / 2))\n",
        "        rbuff = int(math.floor((ysize - xsize) / 2))\n",
        "    else:\n",
        "      print(\"already square\")\n",
        "      tbuff = 0\n",
        "      bbuff = 0\n",
        "      lbuff = 0\n",
        "      rbuff = 0\n",
        "\n",
        "    img = cv2.copyMakeBorder(\n",
        "        img,\n",
        "        top = tbuff,\n",
        "        bottom = bbuff,\n",
        "        left = lbuff,\n",
        "        right = rbuff,\n",
        "        borderType = cv2.BORDER_CONSTANT,\n",
        "        value = (255, 255, 255)\n",
        "    )\n",
        "\n",
        "    cv2_imshow(img)\n",
        "\n",
        "    assert img.shape[0] == img.shape[1] # img must be square\n",
        "\n",
        "    for score in v.get_image_score():\n",
        "      name = str(score.item())\n",
        "      # cv2.imwrite(inference_output_dir + name[2:6] + \".jpg\", img)    # named after accuracy\n",
        "      # cv2.imwrite(inference_output_dir + image_name, img)    # same name\n",
        "      # cv2.imwrite(inference_output_dir + image_name[:-4] + \".png\", img)    # same name - convert to png\n",
        "  else:\n",
        "    print(\"no tree found\")\n",
        "    v2 = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    img = v2.get_image()\n",
        "    cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make backgrounds of images transparent"
      ],
      "metadata": {
        "id": "xIMxhqS2v2B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "input_dir = \"/content/drive/MyDrive/_output/_detectron/using_stylegan_background_input_data/first_pass/\"\n",
        "output_dir = \"/content/drive/MyDrive/_output/_detectron/using_stylegan_background_input_data/second_pass/\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for img in os.listdir(input_dir):\n",
        "  image_name = img\n",
        "  print(image_name[:-4])\n",
        "  # img = cv2.imread(os.path.join(input_dir, img))\n",
        "  img = Image.open(os.path.join(input_dir, img))\n",
        "  # img = Image.open('reals.png')\n",
        "  rgba = img.convert(\"RGBA\")\n",
        "  datas = rgba.getdata()\n",
        "    \n",
        "  newData = []\n",
        "  for item in datas:\n",
        "      if item[0] == 255 and item[1] == 255 and item[2] == 255:\n",
        "          newData.append((255, 255, 255, 0))\n",
        "          # newData.append((255, 0, 0))\n",
        "      else:\n",
        "          newData.append(item)\n",
        "    \n",
        "  rgba.putdata(newData)\n",
        "  rgba.save(output_dir + image_name[:-4] + \".png\")"
      ],
      "metadata": {
        "id": "P7IaebCsDZ9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wudcJ8iUL-O_"
      },
      "source": [
        "#### Crop Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZnidQwaUfwd"
      },
      "outputs": [],
      "source": [
        "# CROPPING IMAGES ONLY\n",
        "\n",
        "os.makedirs(\"/content/detectron_output_masked\", exist_ok=True)\n",
        "\n",
        "dir = \"/content/extracted/categorised_both\"\n",
        "\n",
        "for img in os.listdir(dir):\n",
        "  # print(\"-----\" + img + \"-----\")\n",
        "  image_name = img\n",
        "  img = cv2.imread(os.path.join(dir, img))\n",
        "\n",
        "  xsize = img.shape[1]\n",
        "  ysize = img.shape[0]\n",
        "  if (xsize != ysize):\n",
        "    lsize = max(xsize, ysize)\n",
        "    if (xsize == lsize):\n",
        "      tbuff = int(math.ceil((xsize - ysize) / 2))\n",
        "      bbuff = int(math.floor((xsize - ysize) / 2))\n",
        "      lbuff = 0\n",
        "      rbuff = 0\n",
        "    elif (ysize == lsize):\n",
        "      tbuff = 0\n",
        "      bbuff = 0\n",
        "      lbuff = int(math.ceil((ysize - xsize) / 2))\n",
        "      rbuff = int(math.floor((ysize - xsize) / 2))\n",
        "  else:\n",
        "    # print(\"already square\")\n",
        "    tbuff = 0\n",
        "    bbuff = 0\n",
        "    lbuff = 0\n",
        "    rbuff = 0\n",
        "\n",
        "  img = cv2.copyMakeBorder(\n",
        "      img,\n",
        "      top = tbuff,\n",
        "      bottom = bbuff,\n",
        "      left = lbuff,\n",
        "      right = rbuff,\n",
        "      borderType = cv2.BORDER_CONSTANT,\n",
        "      value = (255, 255, 255)\n",
        "  )\n",
        "\n",
        "  # cv2_imshow(img)\n",
        "  cv2.imwrite(\"./detectron_output_masked/\" + image_name, img)\n",
        "\n",
        "  assert img.shape[0] == img.shape[1] # img must be square"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsB6D82QMhrB"
      },
      "source": [
        "#### Draw Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE_xZtThzyZN"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"/content/detectron_output_masked\", exist_ok=True)\n",
        "\n",
        "img = cv2.imread(\"/content/2.png\")\n",
        "\n",
        "outputs = predictor(img)\n",
        "\n",
        "v = Visualizer(img[:, :, ::-1],\n",
        "                metadata=microcontroller_metadata, \n",
        "                scale=1.0, \n",
        "                instance_mode=ColorMode.IMAGE_BW\n",
        ")\n",
        "\n",
        "v2 = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "# v2 = v.draw_masked_area(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "img = v2.get_image()\n",
        "cv2_imshow(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TreeRecognition_Uploaded.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}